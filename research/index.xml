<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research Themes | Debjit Pal</title>
    <link>https://paldebjit.github.io/research/</link>
      <atom:link href="https://paldebjit.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Research Themes</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© Debjit Pal 2021</copyright><lastBuildDate>Wed, 15 Sep 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://paldebjit.github.io/media/icon_hu2a840fe0f7459a38642b729a88214fad_284883_512x512_fill_lanczos_center_2.png</url>
      <title>Research Themes</title>
      <link>https://paldebjit.github.io/research/</link>
    </image>
    
    <item>
      <title>Application of ML</title>
      <link>https://paldebjit.github.io/research/ml_and_dsl/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://paldebjit.github.io/research/ml_and_dsl/</guid>
      <description>&lt;h4 id=&#34;application-of-ml-in-pre-silicon-verification&#34;&gt;Application of ML in Pre-Silicon Verification&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
The quality of design verification is as good as the verification artifacts. There are multiple such artifacts, including tests, assertions, checker modules. It takes many months to develop such well-crafted artifacts for high-quality verification. In this research, (&lt;a href=&#34;https://paldebjit.github.io/publication/tcad-2020-1&#34; target=&#34;_blank&#34;&gt;TCAD&#39;20b&lt;/a&gt;, &lt;a href=&#34;https://paldebjit.github.io/publication/aspdac-2019&#34; target=&#34;_blank&#34;&gt;ASP-DAC&#39;19&lt;/a&gt;) we applied machine learning for generating assertions automatically for hardware designs and implemented a prototype tool called &lt;a href=&#34;http://goldmine.csl.illinois.edu&#34; target=&#34;_blank&#34;&gt;GoldMine&lt;/a&gt;. Assertion generation refers to the automation of the manual, tedious, ad-hoc, and incomplete process of writing assertions. The principle of GoldMine is simple but powerful. We guide machine learning algorithms by statically analyzing the state space of the system. The domain knowledge of the static analysis algorithms and formal verification could be leveraged as an oracular, iterative mechanism to direct the learning process. This interaction between a statistical inductive inference engine and a static analysis engine could be used repeatedly to generate assertions that surpass manual assertions in quality.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
One of the key tasks of verification is root causing and debugging. However, root causing and debugging are often performed in an unsystematic and ad hoc way under aggressive time-to-market schedules and incur disproportionate costs. In this research, (&lt;a href=&#34;https://paldebjit.github.io/publication/vlsi-2016&#34; target=&#34;_blank&#34;&gt;VLSID&#39;16&lt;/a&gt;) we extend the GoldMine principle and develop an automatic bug localization technique in RTL. Our technique is based on identifying statistically relevant common symptoms across failing simulation trace through data mining, and mapping these back to the corresponding execution paths in the RTL source code.
&lt;/p&gt;
&lt;h4 id=&#34;application-of-ml-in-post-silicon-validation&#34;&gt;Application of ML in Post-Silicon Validation&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Post-silicon validation is a crucial component of contemporary System-on-Chip (SoC) validation and debugging. It is performed in an unsystematic and ad hoc way under aggressive time-to-market schedules. An expensive component of post-silicon validation is application-level use-case validation. In this activity, a validator exercises various target usage scenarios of the system (e.g., for a smartphone, playing videos, or surfing the Web, while receiving a phone call) and monitors for failures (e.g., hangs, crashes, deadlocks, overflows, etc.). However, it is tedious and error-prone to investigate such failure traces containing traces from multiple concurrently executing on-chip components. In this research, (&lt;a href=&#34;https://paldebjit.github.io/publication/dac-2018&#34; target=&#34;_blank&#34;&gt;DAC&#39;18&lt;/a&gt;, &lt;a href=&#34;https://paldebjit.github.io/publication/corr-abs-2021&#34; target=&#34;_blank&#34;&gt;CoRR&#39;21&lt;/a&gt;) we have developed an automatic, scalable, and efficient post-silicon debug and diagnosis solution by applying feature engineering-based machine learning techniques on the failure traces. The idea is to learn the correct and erroneous design behavior automatically from trace data without prior design knowledge. We believe our debugging solution can automate post-silicon debug and diagnosis, where manual debugging is the norm.
&lt;/p&gt;
&lt;h4 id=&#34;application-of-ml-in-hardware-resiliency&#34;&gt;Application of ML in Hardware Resiliency&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Progressive technology scaling and lowering operating voltages have made current and future computer systems more susceptible to high-energy particles induced soft errors (i.e., transient hardware faults). Traditionally, soft error estimation approaches primarily focus on fault injection (FI) campaigns and analytical models. Given realistic program contains billions of instructions, FI incurs a long time to achieve statistically significant results. Alternatively, analytical models can identify vulnerable instructions fast but are inaccurate and suffer from scalability. Recently, ML methods are increasingly used to estimate instruction vulnerability. However, each of these methods suffers from high accuracy loss, small training datasets, and requires time-consuming retraining for unseen programs making them in-feasible for realistic program vulnerability estimation. In this research, (&lt;a href=&#34;https://paldebjit.github.io/publication/date-2021&#34; taregt=&#34;_blank&#34;&gt;DATE&#39;21&lt;/a&gt;) we have developed GLAIVE, an inductive graph learning assisted model that is scalable to large programs containing millions of instructions, can quickly and accurately estimate instruction vulnerability, and can be transferred to unseen programs without retraining.
&lt;/p&gt;
&lt;h4 id=&#34;application-of-ml-in-fpga-qor-estimation&#34;&gt;Application of ML in FPGA QoR Estimation&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Modern heterogeneous FPGA architectures incorporate a variety
of hardened blocks, such as DSP blocks and carry blocks, to boost the performance of arithmetic-intensive designs. Since one can configure hardened blocks in different ways, a variety of datapath patterns can be mapped into these blocks. Existing high-level synthesis (HLS) tools, such as Vivado HLS, often fail to capture many such operation mapping patterns, leading to limited resource usage and delay estimation accuracy. In this research, (&lt;a href=&#34;https://paldebjit.github.io/publication/iccad-2020&#34; target=&#34;_blank&#34;&gt;ICCAD&#39;20&lt;/a&gt;) we propose to exploit graph-neural networks (GNN) to learn operation mapping patterns automatically. We apply GNN models that are trained on microbenchmarks directly to realistic designs through inductive learning. Our learned model can effectively infer various valid mapping patterns on both microbenchmarks and realistic designs. Furthermore, we leverage the proposed framework to improve the accuracy of delay estimation in HLS.
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hardware Verification</title>
      <link>https://paldebjit.github.io/research/verif_and_rel/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://paldebjit.github.io/research/verif_and_rel/</guid>
      <description>&lt;h4 id=&#34;system-on-chip-soc-validation&#34;&gt;System-on-Chip (SoC) Validation&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
System-on-Chips (SoCs) constitutes the primary backbone of modern embedded computing devices including many safety-critical applications e.g., autonomous vehicles, health care systems. The presence of any undetected bugs in these systems would have aberrant cost both in terms of safety and reliability and can cause loss of property or life.  Hence, SoC validation is a crucial task to ensure the functional correctness of an SoC. The sheer size, presence of hundreds of concurrently executing heterogeneous IPs, vertical integration of SoC components e.g., hardware/firmware/software to realize multiple functionality, and application-level relevance of components present a new spectrum of validation challenges that have rendered the traditional microprocessor validation paradigm moot in the context of SoC validation. The challenges include observability enhancement and debug and diagnosis under the constraint of vertical integrations, identifying high-quality verification artifacts among others. In industrial practice, SoC validation is a manual, unsystematic, and ad hoc process that heavily relies on the expertise and the creativity of the validator. Consequently, there is an urgent need to develop scalable and efficient algorithms of industrial relevance to address this massive ongoing challenge of SoC validation.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In my research, we made contributions to both post-silicon and pre-silicon validation of SoCs, with highly impactful contributions to next-generation post-silicon SoC validation. We use top-down analysis, a higher level of abstraction, and application relevance as the key ideas to automate post-silicon observability enhancement for industrial scale SoCs. We scaled observability to designs that are more than 300$\times$ the size of designs that have been presented in the academic literature so far. Our observability enhancement solution can be applied at the netlist-level, behavioral level (&lt;a href=&#34;https://paldebjit.github.io/publication/iccad-2015&#34; target=&#34;_blank&#34;&gt;ICCAD&#39;15&lt;/a&gt;, &lt;a href=&#34;https://paldebjit.github.io/publication/tcad-2020-2&#34; target=&#34;_blank&#34;&gt;TCAD&#39;20a&lt;/a&gt;), and at the system-wide application level (&lt;a href=&#34;https://paldebjit.github.io/publication/dac-2018&#34; target=&#34;_blank&#34;&gt;DAC&#39;18&lt;/a&gt;) to select high-quality signals that are most beneficial for post-silicon debug and diagnosis. We apply a feature engineering based machine learning technique on the observed signal data to develop an automatic, scalable, and efficient post-silicon debug and diagnosis solution. The key idea is to learn the correct and erroneous design behavior automatically from trace data without prior design knowledge. We believe our debugging solution can automate post-silicon debug and diagnosis, where manual debugging is the norm. 
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
The quality of SoC verification and validation heavily depends on the quality of verification artifacts e.g., assertions. To automate and expedite identification of high-functional coverage assertions that are useful for regression analysis, localization, etc., we have also developed a comprehensive ranking scheme for assertions (&lt;a href=&#34;https://paldebjit.github.io/publication/tcad-2020-1&#34; target=&#34;_blank&#34;&gt;TCAD&#39;20b&lt;/a&gt;, &lt;a href=&#34;https://paldebjit.github.io/publication/aspdac-2019&#34; target=&#34;_blank&#34;&gt;ASP-DAC&#39;19&lt;/a&gt;, &lt;a href=&#34;https://paldebjit.github.io/publication/vlsi-2016/&#34; target=&#34;_blank&#34;&gt;VLSID&#39;16&lt;/a&gt;). The key idea is to identify assertions that capture important design behaviors by analyzing the design source code.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Our SoC validation solutions are scalable and efficient. We consistently show orders of magnitude speedup improvements over the state-of-the-art while objectively improving quality of results. We have shown that going forward application-level analysis is the key to scale post-silicon validation to industrial scale SoCs. Our proposed validation solutions can plug into the existing industrial validation process to introduce automation in the current unsystematic, ad hoc, manual settings with multiple order of magnitudes of benefit.
&lt;/p&gt;
&lt;h4 id=&#34;heading&#34;&gt;&lt;/h4&gt;
&lt;h4 id=&#34;hardware-reliability-estimation&#34;&gt;Hardware Reliability Estimation&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Due to the continuous technology scaling and lowering of operating voltages, modern computer systems are highly vulnerable to soft errors induced by the high-energy particles. Soft errors can corrupt program outputs leading to silent data corruption or a Crash. To protect computer systems against such failures, architects need to precisely and quickly identify vulnerable program instructions that need to be protected. Traditional techniques for program reliability estimation either use expensive and time-consuming fault injection or inaccurate analytical models to identify the program instructions that need to be protected against soft errors. In this research (&lt;a href=&#34;publication/date-2021&#34; target=&#34;_blank&#34;&gt;DATE&#39;21&lt;/a&gt;), we present a fast and accurate soft-error induced instruction vulnerability estimation. We leverage a synergy between static analysis and data-driven statistical reasoning to automatically learn signatures of instruction-level vulnerabilities and their propagation to program outputs using a fine-grain error propagation information from the bit-level program graphs of a set of realistic benchmarks.
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Security Analysis</title>
      <link>https://paldebjit.github.io/research/security/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://paldebjit.github.io/research/security/</guid>
      <description>&lt;h4 id=&#34;trojan-detection-in-third-party-ip&#34;&gt;Trojan Detection in Third-Party IP&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Most modern microelectronic systems are designed through
a System-on-Chip (SoC) architecture, which realizes system
functionality within a single substrate by integration and
coordination of pre-designed hardware blocks (referred to as
``Intellectual Properties&#39;&#39; or ``IP&#39;&#39;s). In current practice, the
IPs are procured from a complex, globally distributed supply
chain of third-party IP (3PIP) vendors distributed across the globe. However, the global complex supply chains involved in 3PIP development and delivery make it difficult to ensure the quality and trustworthiness of 3PIPs. A key problem is the vulnerability of these IPs to hardware Trojans, i.e., malicious circuitry intended to subvert the security and integrity of the system. In this ongoing research, we are developing a comprehensive Trojan detection framework based on formal methods for certification of 3PIPs against Trojans. Our approach is flexible, e.g., the
same methodology can be used to detect a spectrum of Trojans
in arbitrary 3PIPs. Our approach works on hardware designs at both
RTL and gate-level netlists enabling early trust verification of
procured 3PIPs before layout and synthesis. A key feature of
our methodology is quantifiable assurance, i.e., if our methodology does
not detect a Trojan, it provides a mathematical certification
stipulating the absence of the Trojan. Consequently, the approach 
enables an SoC integration team to use 3PIPs procured
from an untrusted third-party vendor with confidence that it
does not contain malicious circuitry.
&lt;/p&gt;
&lt;h4 id=&#34;automatic-generation-of-security-assertions&#34;&gt;Automatic Generation of Security Assertions&lt;/h4&gt;
&lt;p align=&#34;justify&#34;&gt;
Modern SoCs contain numerous IPs that participate in complex operations, communications, and co-ordinations with each other to deliver the expected functionality. Various security assets often govern all these features that worth protecting from adversaries. Due to feature diversity, customization, and convoluted interactions among hardware IPs, the SoC can suffer from various security vulnerabilities that allow an adversary to perform unauthorized access, execute malicious modifications, or/and influence the confidentiality and availability of the security assets in the field. The increasing SoC design complexity and shrinking time-to-market make it more challenging to ensure security within the limited verification and solution scope. In this ongoing research, we are developing a comprehensive automatic security assertion generation framework for RTL on top of &lt;a href=&#34;http://goldmine.csl.illinois.edu&#34; target=&#34;_blank&#34;&gt;GoldMine&lt;/a&gt; to formally describe the design&#39;s expected behavior in the context of protecting security assets. Our objective is twofold -- to automatically identify various security assets in the design automatically based on the design and user-specified asset list and to use the gathered knowledge about security assets to generate useful security assertions. In this process we use a rule-based inferencing system to automatically prune portions of the design that are irrelevant in the security context, thereby constraining the assertion miner&#39;s search space. This approach can aid security verification by providing a comprehensive list of security properties which is otherwise a daunting task to develop.
&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
